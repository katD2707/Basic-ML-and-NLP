{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rR_RPdtd-iF7"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import pandas\n",
        "import scipy \n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9RTfrxCF-xXo",
        "outputId": "6ec4eea0-7624-48ff-a8c5-58ae547a383b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>A9</th>\n",
              "      <th>A10</th>\n",
              "      <th>A11</th>\n",
              "      <th>A12</th>\n",
              "      <th>A13</th>\n",
              "      <th>A14</th>\n",
              "      <th>A15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36</td>\n",
              "      <td>27</td>\n",
              "      <td>71</td>\n",
              "      <td>8.1</td>\n",
              "      <td>3.34</td>\n",
              "      <td>11.4</td>\n",
              "      <td>81.5</td>\n",
              "      <td>3243</td>\n",
              "      <td>8.8</td>\n",
              "      <td>42.6</td>\n",
              "      <td>11.7</td>\n",
              "      <td>21</td>\n",
              "      <td>15</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>23</td>\n",
              "      <td>72</td>\n",
              "      <td>11.1</td>\n",
              "      <td>3.14</td>\n",
              "      <td>11.0</td>\n",
              "      <td>78.8</td>\n",
              "      <td>4281</td>\n",
              "      <td>3.6</td>\n",
              "      <td>50.7</td>\n",
              "      <td>14.4</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>39</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>29</td>\n",
              "      <td>74</td>\n",
              "      <td>10.4</td>\n",
              "      <td>3.21</td>\n",
              "      <td>9.8</td>\n",
              "      <td>81.6</td>\n",
              "      <td>4260</td>\n",
              "      <td>0.8</td>\n",
              "      <td>39.4</td>\n",
              "      <td>12.4</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>33</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>47</td>\n",
              "      <td>45</td>\n",
              "      <td>79</td>\n",
              "      <td>6.5</td>\n",
              "      <td>3.41</td>\n",
              "      <td>11.1</td>\n",
              "      <td>77.5</td>\n",
              "      <td>3125</td>\n",
              "      <td>27.1</td>\n",
              "      <td>50.2</td>\n",
              "      <td>20.6</td>\n",
              "      <td>18</td>\n",
              "      <td>8</td>\n",
              "      <td>24</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43</td>\n",
              "      <td>35</td>\n",
              "      <td>77</td>\n",
              "      <td>7.6</td>\n",
              "      <td>3.44</td>\n",
              "      <td>9.6</td>\n",
              "      <td>84.6</td>\n",
              "      <td>6441</td>\n",
              "      <td>24.4</td>\n",
              "      <td>43.7</td>\n",
              "      <td>14.3</td>\n",
              "      <td>43</td>\n",
              "      <td>38</td>\n",
              "      <td>206</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   A1  A2  A3    A4    A5    A6    A7    A8    A9   A10   A11  A12  A13  A14  \\\n",
              "0  36  27  71   8.1  3.34  11.4  81.5  3243   8.8  42.6  11.7   21   15   59   \n",
              "1  35  23  72  11.1  3.14  11.0  78.8  4281   3.6  50.7  14.4    8   10   39   \n",
              "2  44  29  74  10.4  3.21   9.8  81.6  4260   0.8  39.4  12.4    6    6   33   \n",
              "3  47  45  79   6.5  3.41  11.1  77.5  3125  27.1  50.2  20.6   18    8   24   \n",
              "4  43  35  77   7.6  3.44   9.6  84.6  6441  24.4  43.7  14.3   43   38  206   \n",
              "\n",
              "   A15  \n",
              "0   59  \n",
              "1   57  \n",
              "2   54  \n",
              "3   56  \n",
              "4   55  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#dataset link\n",
        "url = \"https://people.sc.fsu.edu/~jburkardt/datasets/regression/x28.txt\"\n",
        "names = ['I', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'B'] \n",
        "dataframe = pandas.read_csv(url, delimiter=r\"\\s+\", header=71, names=names)\n",
        "X = dataframe.iloc[:, 1:-1]\n",
        "Y = dataframe.iloc[:, -1]\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O57LsNcF_aYh"
      },
      "outputs": [],
      "source": [
        "#data normalization\n",
        "def normalize_and_add_ones(X):\n",
        "  X = np.array(X)\n",
        "  \n",
        "  X_normalized = (X - np.min(X, axis=0))/(np.max(X, axis=0) - np.min(X, axis=0))\n",
        "  \n",
        "  return np.concatenate((np.ones(X.shape[0]).reshape(-1,1), X_normalized), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZCHWZgsWGenX"
      },
      "outputs": [],
      "source": [
        "#model building\n",
        "class RidgeRegression:\n",
        "  def __init__(self):\n",
        "    return\n",
        "  def fit(self, X_train, Y_train, LAMBDA):\n",
        "    assert len(X_train.shape) == 2 and X_train.shape[0] == Y_train.shape[0]\n",
        "\n",
        "    w = np.linalg.pinv(np.dot(X_train.T,X_train)+LAMBDA*np.eye(X_train.shape[1])).dot(np.dot(X_train.T, Y_train))\n",
        "    \n",
        "    return w\n",
        "\n",
        "  def fit_gradient_descent(self, X_train, Y_train, LAMBDA, learning_rate, max_epoch=100, batch_size=128):\n",
        "    w = np.random.randn(X_train.shape[1])\n",
        "    last_loss = 1e+9\n",
        "\n",
        "    for ep in range(max_epoch):\n",
        "      shuffle_idx = np.random.shuffle(np.arange(X_train.shape[0]))\n",
        "      X_train = X_train[shuffle_idx]\n",
        "      Y_train = Y_train[shuffle_idx]\n",
        "      total_minibatch = int(np.ceil(X_train.shape[0]/batch_size))\n",
        "      for i in range(total_minibatch):\n",
        "        index = i*batch_size\n",
        "        X_train_sub = X_train[index:index+batch_size]\n",
        "        Y_train_sub = Y_train[index:index+batch_size]\n",
        "        grad = X_train_sub.T.dot(np.dot(X_train_sub, w)-Y_train_sub) + LAMBDA*w\n",
        "        w = w - learning_rate*grad\n",
        "      new_loss = self.compute_RSS(self.predict(w, X_train), Y_train)\n",
        "      if abs(new_loss-last_loss) <= 1e-5:\n",
        "        break\n",
        "      last_loss = new_loss\n",
        "    return w\n",
        "    \n",
        "  def predict(self, W, X_new):\n",
        "    X_new = np.array(X_new)\n",
        "    Y_new = X_new.dot(W)\n",
        "    return Y_new\n",
        "  def compute_RSS(self, Y_new, Y_predicted):\n",
        "    loss = 1. / Y_new.shape[0] * \\\n",
        "            np.sum((Y_new - Y_predicted) ** 2)\n",
        "    return loss\n",
        "  def get_the_best_LAMBDA(self, X_train, Y_train):\n",
        "    def cross_validation(num_folds, LAMBDA):\n",
        "      row_ids = np.arange(X_train.shape[0])\n",
        "\n",
        "      #np.split() requires equal divisions\n",
        "      valid_ids = np.split(row_ids[:len(row_ids) - len(row_ids) % num_folds], num_folds)\n",
        "      valid_ids[-1] = np.append(valid_ids[-1], row_ids[len(row_ids) - len(row_ids) % num_folds:])\n",
        "      train_ids = [[k for k in row_ids if k not in valid_ids[i]] for i in range(num_folds)]\n",
        "      aver_RSS = 0\n",
        "\n",
        "      for i in range(num_folds):\n",
        "        valid_part = {'X': X_train[valid_ids[i]], 'Y': Y_train[valid_ids[i]]}\n",
        "        train_part = {'X': X_train[train_ids[i]], 'Y': Y_train[train_ids[i]]}\n",
        "        W = self.fit(train_part['X'], train_part['Y'], LAMBDA)\n",
        "        Y_predicted = self.predict(W, valid_part['X'])\n",
        "        aver_RSS += self.compute_RSS(valid_part['Y'], Y_predicted)\n",
        "      return aver_RSS / num_folds\n",
        "      \n",
        "    def range_scan(best_LAMBDA, minimum_RSS, LAMBDA_values):\n",
        "      for current_LAMBDA in LAMBDA_values:\n",
        "        aver_RSS = cross_validation(num_folds=5, LAMBDA=current_LAMBDA)\n",
        "        if aver_RSS < minimum_RSS:\n",
        "          best_LAMBDA = current_LAMBDA\n",
        "          minimum_RSS = aver_RSS\n",
        "      return best_LAMBDA, minimum_RSS\n",
        "    \n",
        "    best_LAMBDA, minimum_RSS = range_scan(best_LAMBDA=0, minimum_RSS=1e8, LAMBDA_values=range(50))\n",
        "\n",
        "    LAMBDA_values = [k * 1. / 1000 for k in range(\n",
        "        max(0, (best_LAMBDA-1) * 1000), (best_LAMBDA + 1) * 1000, 1)\n",
        "                    ]\n",
        "    \n",
        "    best_LAMBDA, minimum_RSS = range_scan(best_LAMBDA=best_LAMBDA, minimum_RSS=minimum_RSS, LAMBDA_values=LAMBDA_values)\n",
        "\n",
        "    return best_LAMBDA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC1MdqgcPczI",
        "outputId": "dfc41443-7224-47ab-ad04-805824c30cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best lambda: 0.002\n",
            "1527.069807804805\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  Y = Y.to_numpy()\n",
        "  # normalization\n",
        "  X = normalize_and_add_ones(X)\n",
        "  \n",
        "  X_train, Y_train = X[:50], Y[:50]\n",
        "  X_test, Y_test = X[50:], Y[50:]\n",
        "\n",
        "  ridge_regression = RidgeRegression()\n",
        "  best_LAMBDA = ridge_regression.get_the_best_LAMBDA(X_train, Y_train)\n",
        "  print('best lambda:', best_LAMBDA)\n",
        "  W_learned = ridge_regression.fit(X_train=X_train, Y_train=Y_train, LAMBDA=best_LAMBDA)\n",
        "  Y_predicted = ridge_regression.predict(W=W_learned, X_new=X_test)\n",
        "\n",
        "  print(ridge_regression.compute_RSS(Y_new=Y_test, Y_predicted=Y_predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15Angf-uSA6Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RSS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
